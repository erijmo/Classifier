import tensorflow as tf
from sklearn.datasets import make_circles, make_moons, make_blobs, make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import accuracy_score
import numpy as np

def generate_data(dataset):
    if dataset == "Circles":
        X, y = make_circles(n_samples=250, noise=0.2, random_state=54)
    elif dataset == "Moons":
        X, y = make_moons(n_samples=650, noise=0.3, random_state=18)
    elif dataset == "Blobs":
        X, y = make_blobs(n_samples=740, centers=2, random_state=44)
    elif dataset == "Anisotropic":
        X, y = make_classification(n_samples=810, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=11)
        transformation = [[0.6, -0.6], [-0.4, 0.8]]
        X = np.dot(X, transformation)
    elif dataset == "Varied":
        X, y = make_classification(n_samples=440, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=65)
        transformation = [[0.4, -0.6], [-0.4, 0.8]]
        X = np.dot(X, transformation)
    else:
        raise ValueError("Invalid dataset type")
    return X, y

def preprocess_data(X_train, X_test):
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    return X_train_scaled, X_test_scaled

def create_cnn_model(input_shape):
    model = tf.keras.Sequential([
        tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=input_shape),
        tf.keras.layers.MaxPooling1D(2),
        tf.keras.layers.Conv1D(64, 3, activation='relu'),
        tf.keras.layers.MaxPooling1D(2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

def evaluate_model(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)
    _, accuracy = model.evaluate(X_test, y_test, verbose=0)
    return accuracy

def main():
    datasets = ["Circles", "Moons", "Blobs", "Anisotropic", "Varied"]
    results = []

    for dataset in datasets:
        X, y = generate_data(dataset)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        X_train_scaled, X_test_scaled = preprocess_data(X_train, X_test)
        input_shape = X_train_scaled.shape[1:]

        model = create_cnn_model(input_shape)
        accuracy = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)
        results.append((dataset, 'CNN-1D', 'StandardScaler', 'Holdout', accuracy))

    for result in results:
        print(result)

if __name__ == "__main__":
    main()
